{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf672af4",
   "metadata": {},
   "source": [
    "# RAG without UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63312aaf",
   "metadata": {},
   "source": [
    "# 4.1 — Retrieval + Generation (single shot)\n",
    "\n",
    "Goal: Combine retrieval with an LLM call. Encodes the query, retrieves top-k\n",
    "snippets, builds a focused context window, and asks the model to answer using\n",
    "only that context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15198f9",
   "metadata": {},
   "source": [
    "### Step 1 — Load `.env`, import paths, and create the OpenAI client\n",
    "\n",
    "Ensures the API key is read from environment variables (`.env`) and sets up\n",
    "project paths for consistent file locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f634f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv openai sentence-transformers faiss-cpu\n",
    "from dotenv import load_dotenv, find_dotenv; load_dotenv(find_dotenv())\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.paths import RAW, DOCS_LIST, INDEX\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5fb5f8",
   "metadata": {},
   "source": [
    "### Step 2 — Prepare corpus and retrieval components\n",
    "\n",
    "Loads filenames + texts from `RAW`, initializes `all-MiniLM-L6-v2`, and opens the\n",
    "persisted FAISS `INDEX` for fast nearest-neighbor search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbcd1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ln.strip() for ln in Path(DOCS_LIST).read_text(encoding=\"utf-8\").splitlines() if ln.strip()]\n",
    "doc_paths = [RAW / n for n in names]\n",
    "docs_text = [p.read_text(encoding=\"utf-8\") for p in doc_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804833ca",
   "metadata": {},
   "source": [
    "### Step 3 — Encode query, search FAISS, and build the context window\n",
    "\n",
    "Encodes the query with normalized embeddings, searches FAISS (cap `k` at\n",
    "`index.ntotal`), filters valid indices, and concatenates the retrieved snippets\n",
    "into a single context string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f35fbcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: ['clinical_demo.md']\n",
      "Index ntotal: 1\n"
     ]
    }
   ],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "index   = faiss.read_index(str(INDEX))\n",
    "\n",
    "print(\"Docs:\", names)\n",
    "print(\"Index ntotal:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeebcef",
   "metadata": {},
   "source": [
    "### Step 4 — Call the model with context and return the answer + sources\n",
    "\n",
    "Sends the context and question to the LLM with low temperature for factuality.\n",
    "Appends a `Sources:` line derived from the filenames associated with the hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc4408e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top hits: ['clinical_demo.md']\n"
     ]
    }
   ],
   "source": [
    "q = \"What A1c level diagnoses type 2 diabetes?\"\n",
    "qv = encoder.encode([q], normalize_embeddings=True).astype(\"float32\")\n",
    "D, I = index.search(qv, min(3, index.ntotal))\n",
    "print(\"Top hits:\", [names[i] for i in I[0] if 0 <= i < len(docs_text)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
