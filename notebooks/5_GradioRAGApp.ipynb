{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4591d1",
   "metadata": {},
   "source": [
    "# 5.1 — Gradio RAG App (interactive UI)\n",
    "\n",
    "This notebook loads the docs *via* `src.paths`, retrieves with FAISS, and calls OpenAI with context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6293e",
   "metadata": {},
   "source": [
    "Goal: Expose the RAG pipeline behind a simple web UI. Loads the corpus and\n",
    "artifacts, defines a `rag_respond()` function that retrieves + generates, and\n",
    "launches a Gradio app for interactive testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8bfee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv openai sentence-transformers faiss-cpu gradio\n",
    "from dotenv import load_dotenv, find_dotenv; load_dotenv(find_dotenv())\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.paths import RAW, DOCS_LIST, EMBED, INDEX\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bafa106",
   "metadata": {},
   "source": [
    "### Step 2 — Load filenames and texts from the corpus\n",
    "\n",
    "Reads filenames from `docs_list.txt`, verifies each file exists under `RAW`,\n",
    "loads the texts into memory, and prints a short preview for sanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4efd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using list: /Users/priya/VSCode/Python/Personal Projects/RAG Multimodal Chatbot/Complete RAG folder/data/raw/docs_list.txt\n",
      "clinical_demo.md\n",
      "\n",
      "RAW has: ['docs_list.txt', 'clinical_demo.md']\n"
     ]
    }
   ],
   "source": [
    "# set the list to just real file name\n",
    "Path(DOCS_LIST).write_text(\"clinical_demo.md\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# sanity check\n",
    "print(\"Using list:\", Path(DOCS_LIST).resolve())\n",
    "print(Path(DOCS_LIST).read_text())\n",
    "print(\"RAW has:\", [p.name for p in Path(RAW).glob(\"*\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff843dc",
   "metadata": {},
   "source": [
    "### Step 3 — Prepare encoder, embeddings, and FAISS index\n",
    "\n",
    "Initializes `all-MiniLM-L6-v2`, loads `EMBED` (NumPy array), and opens `INDEX`\n",
    "(FAISS). Prints shapes/`ntotal` to confirm artifact consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd63a897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using paths:\n",
      " RAW: /Users/priya/VSCode/Python/Personal Projects/RAG Multimodal Chatbot/Complete RAG folder/data/raw\n",
      " DOCS_LIST: /Users/priya/VSCode/Python/Personal Projects/RAG Multimodal Chatbot/Complete RAG folder/data/raw/docs_list.txt\n",
      " EMBED: /Users/priya/VSCode/Python/Personal Projects/RAG Multimodal Chatbot/Complete RAG folder/data/processed/embed.npy\n",
      " INDEX: /Users/priya/VSCode/Python/Personal Projects/RAG Multimodal Chatbot/Complete RAG folder/data/processed/faiss_doc_index.index\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv openai sentence-transformers faiss-cpu gradio numpy\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())  # reads .env from repo root\n",
    "\n",
    "# Make ../src importable when running from Complete RAG folder/notebooks/\n",
    "import sys\n",
    "from pathlib import Path\n",
    "parent = Path.cwd().parent\n",
    "if str(parent) not in sys.path:\n",
    "    sys.path.append(str(parent))\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from environment\n",
    "\n",
    "from src.paths import RAW, DOCS_LIST, EMBED, INDEX\n",
    "print(\"Using paths:\")\n",
    "print(\" RAW:\", RAW)\n",
    "print(\" DOCS_LIST:\", DOCS_LIST)\n",
    "print(\" EMBED:\", EMBED)\n",
    "print(\" INDEX:\", INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bbd4991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded docs: ['clinical_demo.md']\n",
      "First doc preview:\n",
      " # Clinical Knowledge Pack (Demo)\n",
      "_This is an educational demo for a local RAG prototype. Not medical advice._\n",
      "\n",
      "## FAQ\n",
      "- **What is this?** Retrieval notes the bot uses to answer questions with citations.\n",
      "- **Scope:** Common chronic conditions + labs and a tiny antibiotic cheat sheet.\n",
      "- **Update caden\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.paths import RAW, DOCS_LIST\n",
    "\n",
    "# read raw lines\n",
    "raw_lines = [ln.strip() for ln in Path(DOCS_LIST).read_text(encoding=\"utf-8\").splitlines() if ln.strip()]\n",
    "\n",
    "# keep only real filenames (exist in RAW or look like files)\n",
    "def looks_like_file(name: str) -> bool:\n",
    "    return any(name.endswith(ext) for ext in (\".md\", \".txt\", \".pdf\")) or (RAW / name).exists()\n",
    "\n",
    "names = [ln for ln in raw_lines if looks_like_file(ln)]\n",
    "if not names:\n",
    "    # fallback to your known file\n",
    "    names = [\"clinical_demo.md\"]\n",
    "\n",
    "# validate existence\n",
    "doc_paths = [RAW / n for n in names]\n",
    "for p in doc_paths:\n",
    "    assert p.exists(), f\"Missing source file: {p}\"\n",
    "\n",
    "# auto-fix docs_list.txt to the cleaned names\n",
    "Path(DOCS_LIST).write_text(\"\\n\".join(names) + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# load texts\n",
    "docs_text = [p.read_text(encoding=\"utf-8\") for p in doc_paths]\n",
    "print(\"Loaded docs:\", names)\n",
    "print(\"First doc preview:\\n\", docs_text[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916cae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1, 384) | Index ntotal: 1\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np, faiss\n",
    "\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeds = np.load(EMBED).astype(\"float32\")\n",
    "index  = faiss.read_index(str(INDEX))\n",
    "print(\"Embeddings shape:\", embeds.shape, \"| Index ntotal:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5918600",
   "metadata": {},
   "source": [
    "### Step 4 — Retrieve, ground the answer in context, and cite sources\n",
    "\n",
    "Encodes the query with normalized embeddings, searches FAISS (cap `k` at\n",
    "`index.ntotal`), builds the context from retrieved texts, calls the LLM, and\n",
    "returns the answer with a `Sources:` line showing the contributing files.\n",
    "Includes a guard to handle empty results or artifact mismatches gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ce3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def rag_respond(q: str) -> str:\n",
    "    try:\n",
    "        # 1) Retrieve top-k\n",
    "        qv = encoder.encode([q], normalize_embeddings=True).astype(\"float32\")\n",
    "        D, I = index.search(qv, 3)\n",
    "        hits = [i for i in I[0] if i >= 0]\n",
    "        if not hits:\n",
    "            return \"No results found in the knowledge base.\"\n",
    "\n",
    "        # 2) Build context strictly from retrieved text\n",
    "        context = \"\\n\\n\".join(docs_text[i] for i in hits)\n",
    "\n",
    "        # 3) Ask OpenAI with the retrieved context\n",
    "        prompt = f\"\"\"Use ONLY the context to answer the question. \n",
    "Be concise and cite specifics.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {q}\n",
    "Short answer:\"\"\"\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":\"You are a careful assistant. Do not invent facts outside the provided context.\"},\n",
    "                {\"role\":\"user\",\"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        answer = resp.choices[0].message.content\n",
    "\n",
    "        sources = \", \".join(dict.fromkeys(names[i] for i in hits))\n",
    "        return f\"{answer}\\n\\n---\\nSources: {sources}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c07ae",
   "metadata": {},
   "source": [
    "### Step 5 — Verify inputs and artifacts before launching\n",
    "\n",
    "Prints loaded filenames, confirms files exist on disk, and checks that both\n",
    "`EMBED` and `INDEX` are present. Useful for catching path or version issues early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bfedbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ['clinical_demo.md']\n",
      "Files exist: [True]\n",
      "Embeddings exist: True Index exists: True\n"
     ]
    }
   ],
   "source": [
    "# Quick checks to show  filename(s) and that artifacts exist.\n",
    "from pathlib import Path\n",
    "print(\"Names:\", names)\n",
    "print(\"Files exist:\", [p.exists() for p in doc_paths])\n",
    "print(\"Embeddings exist:\", Path(EMBED).exists(), \"Index exists:\", Path(INDEX).exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b3876",
   "metadata": {},
   "source": [
    "### Step 6 — Launch the interactive app and test prompts\n",
    "\n",
    "Starts the Gradio interface. Uses `prevent_thread_lock=True` so later cells (e.g.,\n",
    "debug tools) can still run in the same kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d6c49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=rag_respond,\n",
    "    inputs=gr.Textbox(label=\"Ask a Question\"),\n",
    "    outputs=gr.Textbox(label=\"Answer\"),\n",
    "    title=\"RAG Chatbot\",\n",
    "    description=\"Ask a question based on the embedded document knowledge base.\"\n",
    ")\n",
    "\n",
    "# Non-blocking so later cells can still run\n",
    "demo.launch(quiet=True, prevent_thread_lock=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try these test prompts\n",
    "- *What A1c level diagnoses type 2 diabetes?* → expects ≥ 6.5%  \n",
    "- *Typical A1c target and monitoring cadence?* → ~7%; q3 months until target, then q6 months  \n",
    "- *What are first-line meds for uncomplicated hypertension?* → Thiazide, ACEi/ARB, or CCB  \n",
    "- *Normal ALT and AST ranges?* → ALT 7–56 U/L; AST 10–40 U/L\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
